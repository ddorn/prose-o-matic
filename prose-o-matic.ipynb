{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import jsonlines\n",
    "from time import ctime\n",
    "from pathlib import Path\n",
    "from sys import getsizeof\n",
    "from main import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55678175"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = Path('fanfic-pack/')\n",
    "PILE = Path('/extra/diego/the-pile/29.jsonl')\n",
    "\n",
    "def take(n, iterable):\n",
    "    for _, x in zip(range(n), iterable):\n",
    "        yield x\n",
    "\n",
    "def dataset():\n",
    "    for doc in take(10000, jsonlines.open(PILE)):\n",
    "        yield doc['text']\n",
    "    # files = list(DATA.iterdir())\n",
    "    # random.shuffle(files)\n",
    "    # print(f'Loaded {len(files)} files.')\n",
    "    # for f in files:\n",
    "    #     yield f.read_text()\n",
    "\n",
    "sum(map(len, dataset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = BPE.train_from_text(dataset(), 10000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.save('bpe.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200]) torch.Size([1, 1])\n",
      "loss torch.Size([1, 236]) torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5697,  1.1805, -0.1787,  0.2743, -0.7198,  1.1912, -0.0924, -0.3370,\n",
       "           0.8045,  0.7888,  0.7102, -0.3272, -0.1789,  0.6535,  0.3931, -1.0462,\n",
       "          -0.0220, -0.1349,  1.0926, -0.6776, -0.7594, -0.0354, -0.0374, -0.5709,\n",
       "           0.5235, -0.1391,  0.3012,  0.5669, -0.5727, -0.4615, -0.1906, -1.1453,\n",
       "          -0.1955,  0.7128,  0.1855,  0.6050, -0.1329, -0.1400,  0.0680, -0.1281,\n",
       "           0.2070, -0.6633,  0.0347,  0.7938, -0.0366, -0.2556, -0.0637,  0.5921,\n",
       "          -0.8223,  0.7069, -0.1501, -0.2621,  0.2692,  0.3143, -0.1894, -0.1705,\n",
       "           0.6211,  0.1086,  0.2250, -0.6639, -1.2711, -0.3753, -0.3558,  0.1611,\n",
       "          -0.3335,  0.0372, -0.7529, -0.9288, -0.3909, -0.1114, -1.0724, -0.1126,\n",
       "           0.1579, -0.0862,  1.6033, -1.0625,  0.5092, -0.3490, -0.6961, -0.0910,\n",
       "          -0.4471, -0.1075, -0.0861, -1.0742,  0.2204,  0.0134, -0.4498, -0.4720,\n",
       "          -0.8749, -0.3079,  0.2842, -0.2900, -0.3999,  0.8656,  0.4945, -1.3167,\n",
       "           0.2708,  1.0577, -0.0968, -0.7415,  0.2840,  0.5191, -0.9143,  0.1934,\n",
       "          -0.1634, -0.3926, -0.2188, -0.2876, -0.0035, -0.0772, -0.3899,  0.9564,\n",
       "           0.3134,  0.0149, -0.6160, -0.2159,  0.4415, -0.4365,  0.1923, -0.2695,\n",
       "          -0.9338, -0.1199,  0.1780,  0.9773,  0.2062,  0.1517,  0.5789,  0.3279,\n",
       "           0.7182, -0.1894,  1.0373, -0.4149, -1.1383,  0.1471, -0.9467,  1.7406,\n",
       "           0.7575, -0.8498, -0.3401,  1.2047, -1.0988, -0.7649,  0.3400, -0.1926,\n",
       "          -0.8825,  0.0172, -0.5121, -0.2356, -0.5296,  0.4668,  0.0175,  0.1830,\n",
       "           0.2643,  0.3253,  0.0969, -0.0779, -0.6818,  0.2811, -0.2701,  0.5947,\n",
       "          -0.2135,  0.4542, -0.1852, -1.2994,  0.2819,  0.4681,  0.0400,  0.3560,\n",
       "           0.3022, -2.1836, -1.0672, -0.9975, -0.6559, -0.0571,  0.3671,  0.3932,\n",
       "           1.1089,  0.3082, -0.2793,  1.1677,  0.3206, -0.5144, -1.0826, -0.6696,\n",
       "          -0.1890, -0.9440,  0.0325,  1.3405,  0.4314,  0.1477,  0.8978,  0.0074,\n",
       "          -0.9004, -0.5735, -0.5528, -0.3152, -0.0134, -0.0172, -0.6061,  0.5574,\n",
       "           0.0268, -1.4901,  0.1933,  1.6127, -0.0927, -1.2284,  0.8717,  0.1378,\n",
       "           0.6867, -0.4842, -0.5794,  0.3555, -0.9003,  0.1364, -0.0582, -0.7790,\n",
       "          -0.5466,  1.7849,  1.8818,  1.5363,  0.0209, -0.0199,  0.1822,  0.3062,\n",
       "           1.1836, -0.7109,  0.4265, -0.4618,  0.0178,  0.4903,  0.1791, -0.6312,\n",
       "           0.0857,  0.6500, -0.5907, -0.8136]], grad_fn=<SliceBackward0>),\n",
       " tensor(5.7631, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BigramModel(bpe.vocab_size, 128)\n",
    "xs = bpe.tokenize([s[:-1]])\n",
    "ys = bpe.tokenize([s[-1]])\n",
    "print(xs.shape, ys.shape)\n",
    "model.loss(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all tokens in GPT-2 vocabulary\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    tokenizer.decode([i])\n",
    "    for i in range(tokenizer.vocab_size)\n",
    "]\n",
    "print(len(words), type(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
